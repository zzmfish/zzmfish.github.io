## 流程
### 初始化
* 每个任务被初始化成一个***Job***，每个Job分为两个阶段：Map阶段和Reduce阶段

### 输入
* `InputSplit`
    * represents the data to be processed by an individual Mapper
    * byte-oriented view
* `RecordReader`
    * reads &lt;key, value&gt; pairs from an InputSplit


### Map
* ***Map阶段***接收<key,value\>形式的输入，产生<key,value\>形式的输出

### Reduce
* ***Reduce阶段***接收<key, (list of values)\>形式的输入，产生<key,value\>形式的输出
* ***shuffle过程***：把相同的key值放在一起

### 输出

![](/images/MapReduce.png)


## 参考
* [MapReduce Tutorial](http://hadoop.apache.org/docs/r2.7.1/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
* [Hadoop MultipleInputs sample usage](http://www.lichun.cc/blog/2012/05/hadoop-multipleinputs-usage/)
* [Accessing Table Data with MapReduce](http://www.cloudera.com/content/cloudera/en/documentation/core/latest/topics/cdh_ig_table_access_mapreduce.html)
* [MapReduce:详解Shuffle过程](http://langyu.iteye.com/blog/992916)